from datetime import datetime
from fastapi import FastAPI 
from bs4 import BeautifulSoup
from typing import List
from fastapi.responses import JSONResponse

import copy
import yfinance as yf
import requests, pandas as pd
import models.Company as Company
import common.aws as Aws


app = FastAPI()

HEADERS = {
    'User-Agent': "1MyCompany MyName my.emai1l@example.com",
    'From': '1my.email@example.com'
}

@app.get("/")
def read_root():
    return {"message": "Hello FastAPI!"}

# S&P500 ìƒìœ„ íšŒì‚¬ ì‹œê°€ ì´ì•¡ìœ¼ë¡œ 20ê°œ ì¶”ì¶œ
@app.get("/getCompanies", response_model=List[Company.Company])
def get_top_sp500_companies():

    # 20ìˆœìœ„ ì¶”ì¶œ
    url = "https://www.hankyung.com/globalmarket/usa-stock-sp500"
    try:
        # HTTP ìš”ì²­ ë³´ë‚´ê¸°
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ

        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')
        companies = []
        # col1 ~ col20ê¹Œì§€ì˜ tdë¥¼ ëª¨ë‘ ì°¾ìŒ
        for i in range(0, 20):
            # ëª¨ë“  'col1' í´ë˜ìŠ¤ë¥¼ ê°€ì§„ tdë¥¼ í•œ ë²ˆì— ê°€ì ¸ì˜¤ê³ , ìƒìœ„ 20ê°œë§Œ ì‚¬ìš©
            symbol_tds = soup.find_all('td', class_='col1')
            if i-1 >= len(symbol_tds):
                continue
            symbol = symbol_tds[i-1].find('a').find('div', class_='symbol').text.strip()
            
            market_cap_tds = soup.find_all('td', class_='txt-rt col6 col-pc')
            market_cap = market_cap_tds[i-1].find('span').text.strip().replace(',', '')
            companies.append(Company.TopCompany(symbol=symbol, market_cap=float(market_cap)))
        #companies.sort(key=lambda x: x.market_cap, reverse=True) ì‹œê°€ì´ì•¡ ë‚´ë¦¼ì°¨ìˆœ
    
    except Exception as e:
        return {f"message":"ì²˜ë¦¬ ì˜¤ë¥˜: {e}"}
    
    # ì •ë³´ ì¶”ì¶œ
    try:
        response = requests.get("https://www.sec.gov/files/company_tickers.json",
                   headers={"User-Agent":"your@email.com"}).json()
        response_df = pd.DataFrame.from_dict(response, orient="index")[["cik_str", "title", "ticker"]]
        # symbolì— "." ê¸°í˜¸ê°€ ìˆìœ¼ë©´ "-"ë¡œ ë³€ê²½
        symbols = [company.symbol.replace('.', '-') for company in companies]
        print(f"ì´ symbol: {len(symbols)}")
        filtered_df = response_df[response_df["ticker"].isin(symbols)]
        print(f"ë§¤ì¹­ëœ íšŒì‚¬ ìˆ˜: {len(filtered_df)}")

        # ë§¤ì¹­ ì•ˆëœ íšŒì‚¬ ì°¾ê¸°
        matched_symbols = set(filtered_df["ticker"])
        unmatched_symbols = [s for s in symbols if s not in matched_symbols]
        print(f"ë§¤ì¹­ ì•ˆëœ íšŒì‚¬: {unmatched_symbols}")

        result = []
        for _, row in filtered_df.iterrows():
            result.append(Company.Company(
                cik_str=str(row['cik_str']),
                title=row['title']
            ))
        return result
    
    except Exception as e:
        return {f"message":"ì²˜ë¦¬ ì˜¤ë¥˜: {e}"}


# íšŒì‚¬ëª… ë°›ì•„ì˜¤ë©´ company ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
@app.get("/getCompanyFacts/{company_code}/{year}/", response_model=List[Company.CompanyFactRecord])
def get_companyfacts(company_code: str, year: int):
    url = f"https://data.sec.gov/api/xbrl/companyfacts/CIK{company_code}.json"
    try:
        print(f"[{company_code}] ë°ì´í„°ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
        response = requests.get(url, headers=HEADERS)
        response.raise_for_status() # 4xx ë˜ëŠ” 5xx ì‘ë‹µ ì½”ë“œì— ëŒ€í•´ HTTPError ë°œìƒ

        data = response.json()
        entity_name = data.get('entityName', 'N/A')
        facts = data.get('facts', {}).get('us-gaap', {})

        min_year = datetime.now().year - year
        records = []
        for concept_name, concept_data in facts.items():
            #description = concept_data.get('description', 'N/A')
            for unit, unit_data_list in concept_data.get('units', {}).items():
                for record in unit_data_list:
                    fy = record.get('fy')
                    if fy is not None and fy >= min_year:
                        records.append(Company.CompanyFactRecord(
                            # ì¬ë¬´í•­ëª©ì´ LINE_ITEMSì— ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ, ì—†ìœ¼ë©´ call_deep_modelë¡œ ë²ˆì—­ í›„ LINE_ITEMSì™€ translate_kr.pyì— ì¶”ê°€
                            company=entity_name,
                            company_number=company_code,
                            fin_item=concept_name, #ì¬ë¬´í•­ëª©
                            #"í•­ëª©ì„¤ëª…": description,
                            unit=unit,
                            value=record.get('val'),
                            start_date=record.get('start'),
                            end_date=record.get('end'),
                            fis_year=fy, #íšŒê³„ì—°ë„
                            fis_quarter=record.get('fp'), # íšŒê³„ë¶„ê¸°
                            fil_document=record.get('form'), # ê³µì‹œì„œë¥˜
                            fil_date=record.get('filed'), # ì œì¶œì¼
                            accession_number=record.get('accn') #ì ‘ìˆ˜ë²ˆí˜¸
                        ))

        res_df = pd.DataFrame([r.dict() for r in records])

        if 'fil_date' in res_df.columns and not res_df['fil_date'].isnull().all():
            res_df.sort_values(by='fil_date', ascending=False, inplace=True)

        # ì—´ëª… ì¹˜í™˜: ì˜ˆì‹œë¡œ ì˜ë¬¸ -> í•œê¸€ë¡œ ë°”ê¿”ì¤Œ. í•„ìš”ì— ë”°ë¼ ë§¤í•‘ ìˆ˜ì •
        csv_df = copy.deepcopy(res_df)

        # ì—´ëª…ë§Œ ë³€ê²½ (ì¹˜í™˜)í•´ì„œ DataFrameì— ë°˜ì˜
        csv_df.columns = [
            "íšŒì‚¬ëª…" if col == "company" else
            "íšŒì‚¬ì½”ë“œ" if col == "company_number" else
            "ì¬ë¬´í•­ëª©" if col == "fin_item" else
            "ë‹¨ìœ„" if col == "unit" else
            "ê°’" if col == "value" else
            "ì‹œì‘ì¼" if col == "start_date" else
            "ì¢…ë£Œì¼" if col == "end_date" else
            "íšŒê³„ì—°ë„" if col == "fis_year" else
            "íšŒê³„ë¶„ê¸°" if col == "fis_quarter" else
            "ê³µì‹œì„œë¥˜" if col == "fil_document" else
            "ì œì¶œì¼" if col == "fil_date" else
            "ì ‘ìˆ˜ë²ˆí˜¸" if col == "accession_number" else col
            for col in csv_df.columns
        ]

        # ë§Œë“  ë‚ ì§œë¥¼ filenameì— ë„£ê¸°
        created_date = datetime.now().strftime("%Y%m%d")
        file_name = f"SEC_{entity_name.replace(' ', '_')}_{created_date}.csv"
        download_url = Aws.upload_csv_to_s3(csv_df, file_name) 

        # download_urlì„ resultì— ë‹´ê³ , res_dfì˜ ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”°ë¡œ ë‹´ì•„ì„œ [{result}, {res_df}] í˜•íƒœë¡œ ë°˜í™˜
        result = [{"download_url": download_url}]
        records = res_df.to_dict(orient="records")
        
        # records ë¦¬ìŠ¤íŠ¸ì˜ [] í•œ êº¼í’€ ë²—ê¸°ê¸°: [{result}, *records] í˜•íƒœë¡œ ë°˜í™˜
        return JSONResponse(content=[result, records])

    except requests.exceptions.HTTPError as e:
        print(f"ğŸš¨ [{company_code}] HTTP ì˜¤ë¥˜: {e}\n")
        return {f"message":"HTTP ì˜¤ë¥˜: {e}"}
    except Exception as e:
        print(f"ğŸš¨ [{company_code}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\n")
        return {f"message":"ì²˜ë¦¬ ì˜¤ë¥˜: {e}"}